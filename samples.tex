% !TEX root = sputnik.tex
\documentclass[sputnik.tex]{subfiles}
\begin{document}

\def\Fr{\mathop{\rm Fr}}

\def\vc{{\footnotesize VC}}
\def\nip{{\footnotesize NIP}}


\def\medrel#1{\parbox[t]{6ex}{$\displaystyle\hfil #1$}}
\def\ceq#1#2#3{\parbox[t]{25ex}{$\displaystyle #1$}\medrel{#2}{$\displaystyle #3$}}



\chapter{Samples and approximations of measures}
%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%


\section{Samples and subsamples}\label{multisets}

\def\ceq#1#2#3{\parbox[t]{32ex}{$\displaystyle #1$}\parbox{5ex}{$\displaystyle\hfil #2$}{$\displaystyle #3$}}

A sample is a just sequence of elements of $\U$ where we disregard the order and only consider the number of times they appear.
Formally, a \emph{sample\/} is a \emph{multiset}, that is is a function $A:\U\to\NN$.
We interpret $A(x)$ as the \emph{multiplicity\/} of the element $x\in\U$.
The \emph{support\/} of $A$ is the set \emph{$\supp(A)$}$=\{x:A(x)\neq0\}$.
The \emph{size of $A$\/} is defined as

\ceq{\hfill\emph{$|A|$}}{=}{\sum_{x\in\U} A(x).}

If we identify sets with $\{0,1\}$-valued samples, the size generalizes cardinality. 

\makeatletter
\def\dotminus{\mathbin{\ooalign{\hidewidth\raise1ex\hbox{.}\hidewidth\cr$\m@th-$\cr}}}
\makeatother

We say that $C$ is a \emph{subsample\/} of $A$, and write \emph{$C\subseteq A$}, if $C(x)\le A(x)$ for all $x\in\U$.
We also define the \emph{intersection\/} and the \emph{difference\/} of two samples.
The element $x\in\U$ has multiplicity  $A(x)\wedge C(x)$ in \emph{$A\cap C$\/} and multiplicity  $A(x)\dotminus C(x)$ in \emph{$A\sm C$}.
Note that $|A|=|A\cap C|+|A\sm C|$.

If $\B\subseteq\U$ we define the \emph{frequency\/} of $\B$ over $A$

\ceq{\hfill\emph{$\Fr\big(\B/A\big)$}}{=}{\frac{\big|\B\cap A\big|}{|A|}}

Note that $\Fr(\cdot/A)$ is a probability measure on $\U$.

An \emph{$\epsilon$-approximation\/} of a sample $A$ is a subsample $C\subseteq A$ such that for every definable set $\B$

\ceq{\hfill\displaystyle \Big|\Fr(\B/A) - \Fr(\B/C)\Big|}{\le}{\epsilon}

With exception of enumerations, the definitions above easily generalize to \emph{fractional samples\/} i.e.,  function with values on the non negative real.
These will be used in the next chapter.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Discrepancy}\label{epsilon_approximations}

Given $\epsilon$ we are interested in the least $n$ such that some $\epsilon\jj$approximations of size $n$ exist.
The idea is to start with an approximation of large size and reduce size at the cost of slightly enlarging $\epsilon$.
We now introduce a powerful technique to achieve this.

In general $\U$ may not be among the definable sets. As it is often convenient to include it, we write \emph{$\Phi'$\/} for $\Phi\cup\{\U\}$.

Let $C\subseteq A$ and $\B\in\Phi'$. We call the quantity 

\ceq{\hfill\emph{$\Delta_{A,C,\B}$}}{=}{\frac{|C\cap\B|-|(A{\sm} C)\cap\B|}{|A|}}

the \emph{discrepancy\/} of $C$ in $\B$. The \emph{relative discrepancy\/} of $C$ in $\B$ is

\ceq{\hfill\emph{$\delta_{A,C,\B}$}}{=}{\frac{\Delta_{A,C,\B}}{|A|}.}

The \emph{relative discrepancy\/} of $C$ is\smallskip

\ceq{\hfill\emph{$\delta_{A,C}$}}{=}{\sup_{\B\in\Phi'}\big|\delta_{A,C,\B}\big|.}

The \emph{relative discrepancy\/} of $A$ is 

\ceq{\hfill \emph{$\delta_A$}}{=}{\inf_{C\subseteq A}\delta_{A,C}}

The next lemma is intuitive, if an $\epsilon$-approximation has small discrepancy then we can halve its size at a small cost.

\begin{lemma}\label{lem_aprossimazionediapprossimazione}
Let $A$ be a sample of size $n$.
Let $C\subseteq A$ have discrepancy $\delta_{A,C}$.
Then either $C$ or $A\sm C$ is an $\epsilon$-approximation of size $\le n/2$ for $\epsilon=2\delta_{A,C}$.
\end{lemma}

\begin{proof}
%Assume for clarity that $A$ is integral, so infimum and supremum in the definition of $\delta_A$ can be replaced by minimum and maximum.
%It is straightforward to generalize the argument to fractional multi-sets (it is not needed for the application below).

Define $n^+{=}\,|C|$ and  $n^-{=}\,|A{\sm}C|$.
We may assume that $n^+\le n/2$, otherwise swap $C$ and $A\sm C$.
Then $\delta_{A,C,\U}=(n^+-n^-)/n<0$. Now, let $\B\in\Phi'$ be arbitrary

\ceq{\ssf{1.}\hfill\frac{|A\cap\B|}{n}}{=}{\frac{|C\cap\B|\, +\, |(A{\sm}C)\cap\B|}{n}}

\ceq{\hfill(*)}{=}{\frac{2|C\cap\B|}{n}\, -\, \delta_{A,C,\B}}

\ceq{}{\le}{\frac{|C\cap\B|}{n^+}\, +\, \delta_{A,C}}

We also have 

\ceq{\ssf{2.}\hfill(*)}{=}{\frac{|C\cap\B)|}{n^+}\big(1+\delta_{A,C,\U}\big)\,-\,\delta_{A,C,\B}}

\ceq{}{\ge}{\frac{|C\cap\B|}{n^+}\ -\ 2\delta_{A,C}}

Combining \ssf{1} and \ssf{2} we obtain\smallskip

\ceq{\hfill\big|\Fr(\B/A)\ -\ \Fr(\B/C)\big|}{\le}{\left|\frac{|\B\cap A|}{n}\ -\ \frac{|\B\cap C)|}{n^+}\right|}

\ceq{}{\le}{2\delta_{A,C}}\smallskip

as claimed by the lemma.
\end{proof}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Random colorings}

An \emph{enumeration\/} of a sample $A$ is a tuple $a=\<a_1,\dots,a_n\>\in\U^n$ such that

\ceq{\hfill A(x)}{=}{\big|\{i\ :\ a_i=x\}\big|.}

Clearly, all enumerations of $A$ have length $n=|A|$. We write \emph{$\range(a)$} for the sample enumerated by $a$.

Fix an enumeration $a=\<a_1,\dots,a_n\>$ of $A$. A tuple $c=\<c_1,\dots,c_n\>\in\{-1,+1\}^n$ is called a \emph{coloring}. To each coloring $c$ we associate a subsample of $A$ 

\ceq{\hfill C_c(x)}{=}{\big|\{i : a_i=x,\ c_i=+1\}\big|}

Note that the quantity 

\ceq{\hfill\Delta_{a,c,\B}}{=}{\sum_{a_i\in\B}c_i.}

coincide with the discrepancy of $C_c$ over $\B$. As in particular it does not depend the enumeration of $A$, below we will write $\Delta_{A,c,\B}$

When 
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Important inequalities}


\def\ceq#1#2#3{\parbox[t]{15ex}{$\displaystyle #1$}\medrel{#2}{$\displaystyle #3$}}

\begin{void_thm}[Proposition (Weak Law of Large Numbers)]\label{wlln}
Let $\mu$ be a probability measure on $\U$.
Then, for every event $\B\subseteq\U$ and every $n,\epsilon>0$

\ceq{\hfill1-\frac{1}{4n\epsilon^{\scriptscriptstyle 2}}}{<}{\displaystyle\mu^n \Big(c\in\U^n\ :\ \Big|\mu\B - \frac1n\big|c^\circ\cap\B\big| \Big|\le\epsilon\Big)}
\end{void_thm}


\begin{proof}
Note that $X=X(c)=\big|c^\circ\cap\B\big|$ is a binomial random variable with success probability $p=\mu\B$. 
Hence ${\rm E}(X)=p$ and  ${\rm Var}(X)=p(1-p)/n$.
Apply Chebyshev's inequality.
\end{proof}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{A uniform law of large numbers}

\def\ceq#1#2#3{\parbox[t]{35ex}{$\displaystyle #1$}\medrel{#2}{$\displaystyle #3$}}

An \emph{$\epsilon$-approximation\/} of a sample $A$ is a subsample $C\subseteq A$ such that for every definable set $\B$

\ceq{\hfill\displaystyle \Big|\Fr(A,\B) - \Fr(C,\B)\Big|}{\le}{\epsilon}

We want to estimate the minimal size of an $\epsilon$-approximation of $A$.
We want a bound that depends solely on $\epsilon$, not on the size of $A$. It is also important to note requirement of uniformity: the same approximation works for all definable sets.

If we allow $C$ to depend on $\B$, its existence follows easily from the weak law of large numbers.

\def\ceq#1#2#3{\parbox[t]{25ex}{$\displaystyle #1$}\medrel{#2}{$\displaystyle #3$}}

\begin{proposition}[(Weak law of large numbers)]
For every sample $A$, every $\B\subseteq\U$ and every $\epsilon>0$ there is a $C\subseteq A$ of size $n=1/4\,\epsilon^2$ such that $\big|\Fr(A,\B) - \Fr(C,\B)\big|\le\epsilon$.
\end{proposition}
% 
% \begin{proof}
% Apply the weak law of large numbers, Proposition~\ref{wlln},  with $\mu(\B) = \Fr(A,\B)$. If $n\le1/4\,\epsilon^2$ then
% 
% \ceq{\hfill0}{<}{\displaystyle\mu^n \Big(c\in\U^n\ :\ \Big|\mu(\B) - \Fr(B/c)\big| \Big|\le\epsilon\Big)}
% 
% In particular, set above in non empty. The required subsample is $C=c^\circ\cap A$.
% \end{proof}


\begin{proof}
Define $\Pr(\cdot)=\Fr(A,\cdot)$. Fix $\B$ and set $p=\Pr(\B)$. Consider the Bernoulli random variables $X_i$ that on input $c\in\U^n$ output

\ceq{\hfill X_i(c)}{=}{\left\{
\begin{array}{ll}
1&{\rm if}\ c_i\in\B\\
0&{\rm if}\ c_i\notin\B\\
\end{array}\right.}

Define also $\displaystyle\bar X=\frac1n\sum_iX_i$. Then ${\rm E}(\bar X)=p$ and $\displaystyle{\rm Var}(\bar X)=\frac{p(1-p)}{n}\le\frac1{4n}$. 

If we set $C=\range(c)\cap A$, we obtain 

\ceq{\hfill \big|{\rm E}(\bar X)-\bar X(c) \big|}{=}{\big|\Fr(A,\B) - \Fr(\range(c),\B)\big|}

\ceq{}{\ge}{\big|\Fr(A,\B) - \Fr(C,\B)\big|}

So it suffices that $\big|{\rm E}(\bar X) - \bar X\big|\le\epsilon$ has positive probability for some large enough $n$. By Chebychev's inequality


\ceq{\hfill 1-\frac{1}{4n\epsilon^{\scriptscriptstyle 2}}}{<}{\Pr\Big(\big|{\rm E}(\bar X) - \bar X\big|\le\epsilon\Big)}

% By the Chernoff bound
% 
% \ceq{\hfill 1-2\,e^{-2n\epsilon^2}}{<}{\Pr\Big(\big|{\rm E}(\bar X) - \bar X\big|\le\epsilon\Big)}

Hence the probability above is positive for $\displaystyle\frac1{4\epsilon^{\scriptscriptstyle 2}}\le n$.
\end{proof}


\begin{theorem}[(Uniform law of large numbers)]\label{thm_epsilon_approx}
Assume $(\U,\Phi)$ has \vc-density $d$. Then every sample $A$ has an $\epsilon$-approximation of size 

\ceq{\hfill n}{\le}{c\,\frac{d}{\epsilon^{\scriptscriptstyle 2}}\ln\frac1\epsilon,}

where $c$ is an absolute constant.
\end{theorem}



The lemma above tells that $\epsilon$-approximations with small discrepancy are useful, but as yet we have no clue as to finding one.
We are going to prove that when the number of definable subsets of $A$ is relatively small, then the discrepancy of $A$ is not too large.
We use a probabilistic argument to prove this bound (when you don't have a clue how to do something, you might as well do it randomly).

First, we make a brief digression into probability theory.
The following inequality is a classical tool in this context.

\begin{lemma}[(Chernoff's bound, special case)]\label{Chernoff}
For $i=1,\dots,n$ let $X_i$ be independent identically distributed random variables such that\/ $\Pr(X_i=\pm1)=1/2$.
Then for every $\epsilon>0$

\ceq{\hfill \Pr\big(\bar X\ge\epsilon\big)}{\le}{\exp(-\frac{n}{2}\epsilon^2)}\hfill where $\displaystyle \bar X=\frac1n\sum^n_{i=1}X_i$
\end{lemma}
\begin{proof}
Let $t>0$ be arbitrary.
Then

\ceq{\sharp\hfill \Pr(\bar X\ge\epsilon)}{=}{ \Pr\big(e^{t\bar X}\ge e^{t\epsilon}\big)}

\ceq{~}{\le}{e^{-t\epsilon}\,{\rm E}\big(e^{t\bar X}\big)}

In fact, the equality follows because the exponential is an increasing function and the inequality is Markov's inequality, which says that $\Pr(X\ge a)\le a^{-1}{\rm E}(X)$ for every $a$ and is immediate to verify.
Now observe that

\ceq{\hfill {\rm E}\big(e^{tX_i}\big)}{=}{\frac12e^t\ +\ \frac12e^{-t}}

\ceq{~}{=}{\frac12\sum^\infty_{i=0}\frac{t^i}{i!}\ +\ \frac12\sum^\infty_{i=0}\frac{(-t)^{i}}{i!}}

\ceq{~}{=}{\sum^\infty_{i=0}\frac{t^{2i}}{(2i)!}}

\ceq{~}{\le}{\sum^\infty_{i=0}\frac{(t^2/2)^i}{i!}}

\ceq{~}{=}{e^{t^2/2}}

From this, by independence we have 

\ceq{\hfill {\rm E}\big(e^{t\bar X}\big)}{=}{\prod^n_{i=1}e^{(t/n)X_i}}$\medrel{=}e^{t^2/2}$


Subtituting in $\sharp$ gives $\Pr(\bar X\ge\epsilon)\le e^{t^2/2-t\epsilon}$.
Finally Chernoff's inequality is obtained substituting $\epsilon$ for $t$.
\end{proof}


\begin{lemma}\label{lem_discrepanzarandom} 
Let $A$ be a sample of size $\le n$. Assume the support of $A$ has $\le m$  definable subsets. Then $\delta_A\ \le\ \sqrt{(2/n)\ln(m+1)\;}$.
\end{lemma}

\begin{proof}
\def\ceq#1#2#3{\parbox[t]{40ex}{$\displaystyle #1$}\medrel{#2}{$\displaystyle #3$}}
To prove that $\delta_A\le\epsilon$ it suffices to show that there is a $C\subseteq A$ such that $\delta_{A,C,\B}\le\epsilon$ for all $\B$.  It suffices to define a probability on the subsamples of $A$ and show that

\ceq{\hfill \Pr\big(\A\B\in\Phi'\ \ \delta_{A,C,\B}\le \epsilon\big)}{>}{0}

or, as $\Phi'$ has at most $m+1$ elements, that for every $\B\in\Phi'$

\ceq{\ssf{4.}\hfill\Pr\big(\delta_{A,C,\B}\ge\epsilon\big)}{\le}{\frac1{m+2}.}


Suppose $c=\<c_1,\dots,c_n\>\in\{\pm1\}^n$ is obtained tossing $n$ times a fair coin. Fix $\B$ and let $n'=|\B|$. Consider the Bernoulli random variables $X_i$ that on input $c$ output $c_i$. Define also $\displaystyle\bar X=(1/n')\sum_{a_i\in\B} X_i$. Then $\delta_{A,C_c,\B}=\bar X(c)$ and \ssf{4} is equivalent to

\ceq{\hfill\Pr\big(\bar X\ge\epsilon\big)}{\le}{\frac1{m+2}.}


By the Chernoff's bound this is satisfied if 


\ceq{\hfill\exp(-\frac{n'\epsilon^2}{2})}{\le}{\frac1{m+2}.}

As $n'\le n$, this yields the required bound.\end{proof}

\begin{void_thm}[Proof of Proposition \ref{thm_epsilon_approx}]\rm
Set $A_0=A$ and $\epsilon_0=0$. We construct a decreasing chain $A_i$ of $\epsilon_i$-approximations.
We denote by $n_i$ and $\delta_i$ the cardinality, respectively the discrepancy, of $A_i$.
By lemma~\ref{lem_aprossimazionediapprossimazione}, we can require that $\epsilon_{i+1}=\epsilon_i+2\delta_i$ and $n_{i+1}\le n_i/2$.
Then

\ceq{\hfill\epsilon_{h}}{=}{2\sum^h_{i=1}\delta_i}

Let $h$ be the largest such that $\epsilon_h\le\epsilon$. The theorem claims that $\displaystyle 2^{-h}n_0\le c\,(d/\epsilon^2)\log(1/\epsilon)$, independently of $n_0$. 


\ceq{\hfill2\sum^h_{i=1}\delta_i}{\le}{2\sum^h_{i=1}\sqrt{(2/n_i)\ln(n_i^d+2)}}

and, as $n_i=2^{-i}n_0$, the sum above is proportional to its largest term,

\ceq{}{\le}{c\sqrt{(d/n_h)\ln(n_h)}}

Hence a sufficient condition for $\epsilon_h<\epsilon$ is 

\ceq{\hfill c\sqrt{(d/n_h)\ln(n_h)}}{\le}{\epsilon}

which is equivalent to

\ceq{\hfill \frac{c^2 d}{\epsilon^2}}{\le}{\frac{n_h}{\ln n_h}}

this in turn is ensured if

\ceq{\hfill n_h}{\le}{ 2\frac{c^2 d}{\epsilon^2}\ln\frac{c^2 d}{\epsilon^2}}



\end{void_thm}


\begin{corollary}\label{coroll_epsilon_multiapprox}Let $\Phi$ be a finite set-system of \vc-dimension $1<k<\omega$.
Then for every positive $\epsilon<1$, every probability measure $\Pr$ admits a multi-set $\epsilon$-approximation of cardinality bounded by $\natural$ of Theorem~\ref{thm_epsilon_approx}.
\end{corollary}
\begin{proof}
Without loss of generality we can assume that $\Pr$ is rational valued.
Then there is a uniform probability measure $\Pr'$ on some finite set $\U'$ and a surjection $f:\U'\to\U$ such that $\Pr(f^{-1}\phi)=\Pr(\phi)$.
By Theorem~\ref{thm_epsilon_approx} $\Pr'$ admits an $\epsilon\jj$approximation $B'$ with cardinality by $\natural$, for every positive $\epsilon<1$.
We know define a multi-set $B$ such that $B(a)=|B'\cap f^{-1}|$ for every $a\in\U$.
As $|B'|=|B|$ and $|B'\cap f^{-1}\phi|=|B\cap\phi|$, this is the required multi-set $\epsilon$-approximation.
\end{proof}

The following corollary is used in Theorem~\ref{thm_qq} below.
Though it is sufficient for our application, stronger bound are known (essentially, we can replace $\epsilon$ for $\epsilon^2$).



\begin{corollary}\label{coroll_epsilon_net}
Let $\Phi$ be a finite set-system of \vc-dimension $1<k<\omega$.
Then for every positive $\epsilon<1$, every probability measure $\Pr$ admits a multi-set $\epsilon$-net of cardinality bounded by $\natural$ of Theorem~\ref{thm_epsilon_approx}.
\end{corollary}

\begin{exercise}\label{ex_counterexample}
Suppose that $\{a\},\{b\}\in\Phi$ for some $a,b\in\U$.
Show that, if $\Pr$ and $\epsilon$ are such that $0<\epsilon<\Pr(a)$ and $2\epsilon<\Pr(b)-\Pr(a)$, then $\Pr$ admits no $\epsilon\jj$approximation.\QED
\end{exercise}



 
\end{document}
